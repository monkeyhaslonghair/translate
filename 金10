爬金10数据还是有点意思的，这里分享一下爬取过程中的一个小部分，是关于数据提取的问题（为毛要写这个，因为好玩）

这串数据差不多是这样的，这里只截取一部分：
/**/JQ_1532155468({"data":[{"id":"20180721143726645100",
"content":"0#1#2018-07-21 14:37:26#【报道】据新华社，
伊拉克首都巴格达和中南部多个省份的民众20日继续举行游行，
抗议高失业率以及政府服务不力等。当天抗议活动引发的冲突造成1人死亡、41人受伤。
#####0###20180721143726645100","title":"2018年07月21日资讯",
"title_content":"【报道】据新华社，伊拉克首都巴格达和中南部多个省份的民众20日继续举行游行，抗议高失业率以及政府服务不力等。
当天抗议活动引发的冲突造成1人死亡、41人受伤。",
"created_at":"2018-07-21 14:37:27","time_show":"2018-07-21 14:37:26",
"time_humans":"6分钟前","type":0,"pic":null,
"url":"http:\/\/view.jin10.com\/news20180721143726645100.html",
"revise":"","reviseId":null},
{"id":"20180721142439845100",
"content":"0#1#2018-07-21 14:24:39#<a href=\"http:\/\/app.jin10.com\/\" target=\"_blank\">
<img src=\"https:\/\/image.jin10.com\/1531454445.gif\" width=\"754\" height=\"120\" \/>
<\/a>#####0###20180721142439845100","title":"2018年07月21日资讯",
"title_content":"<a href=\"http:\/\/app.jin10.com\/\" target=\"_blank\">
<img src=\"https:\/\/image.jin10.com\/1531454445.gif\" width=\"754\" height=\"120\" \/><\/a>",
"created_at":"2018-07-21 14:24:40","time_show":"2018-07-21 14:24:39","time_humans":"19分钟前",
"type":0,"pic":null,"url":"http:\/\/view.jin10.com\/news20180721142439845100.html","revise":"","reviseId":null},
乍一看显得很凌乱，但是仔细看，它虽然不是json数据，但是还是很有规律的，
除去开头的/**/JQ_1532155468(，从data开始，就是一个字典，data对应的值是一个列表，这个列表中有title，有create_time，有content_title，有url
这些都是我们需要的内容，首先能想到的是正则提取，但是用正则粗暴的提取真的好吗?显然如果用正则提取，就不能把提取出来的数据一一对应，所以得找规律一条一条来
首先可以注意到data对应的内容是一个列表，我们可以通过正则将列表中的数据匹配出来，然后循环遍历，将需要的数据提取出来
有了这个设想，就可以尝试一下
所以首先我用了正则，re.findall("\"data\"\:(.*?)\,\"message\"",html)[0]，正则匹配出的内容必须是一个列表，所以这里取其第一个元素，用[0]
得到的数据是[{"id":"20180721165129788100","content":"0#1#2018-07-21 16:51:29#<b>瑞银：。。。。。（原谅我，后面就省略了）
得到的内容很明显是一个字符串，要是直接进行遍历显然是不行的，只能遍历出[,{,",i,d,:。。。。（继续省略，你懂的）
所以这里需要用到一个函数eval()(别说，这函数真j8强大)，
但是问题出现了，在数据中有null，用eval（）就报错，这玩意python认为它是变量（因为木有引号）
你可能会想，没有就正则替换给它加一个引号不就得了，然而我尝试过，还是不行，这里你可以试试（要是试出来就告诉我）
鉴于这些为null的数据是空，一点不重要，以后也不打算提取，（提取了也没用，本来就是空）所以我用了一串数字进行了替换，（原谅我用了1008611）
然后就可以无障碍使用eval()
得到的数据是[{"id":"20180721165129788100","content":"0#1#2018-07-21 16:51:29#<b>瑞银：。。。。。（不是我写重，本来就是一毛一样，只是格式不一样）
然后就可以遍历了，遍历后数据是这个鸟样：
{'created_at': '2018-07-21 17:14:31',
'url': 'http:\\/\\/view.jin10.com\\/news20180721171430760100.html',
'title_content': '\n【新华社：经贸摩擦难阻美国佐治亚州对华经贸合作期许】尽管对中美经贸摩擦有担忧，但美国东南部佐治亚州仍高度期待加强与中国的经贸往来与合作。多名政商界人士纷纷表示，佐治亚州与中国经贸关系密切，将在此基础上继续寻求与中国在贸易、投资等领域合作。', 
'title': '2018年07月21日资讯'}
首先这url就让人不能忍，要教它做人
所以用一个re.sub将\替换成空
再将title_content中的数据整一整，得到这种：
{'url': 'http://view.jin10.com/news20180721125605829100.html', 
'created_at': '2018-07-21 12:56:06',
'title': '2018年07月21日资讯', 
'title_content': '据《财经》：多数银行已经积极开展相关整改工作。资管新规要求各家银行自行制定整改方案并上报当地监管审批，不少银行的整改方案已报监管通过，但亦有少数银行整改方案未被通过。'}
丫这样就看着舒服多了






